{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#setup data\n",
    "from dataloader import customDataset, create_dataloader, get_sample_weights\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor, RandomResizedCrop\n",
    "from torch.utils.data import random_split, DataLoader, WeightedRandomSampler\n",
    "\n",
    "transforms = Compose([\n",
    "    RandomResizedCrop(size=(256, 256), scale=(0.1, 0.25)),\n",
    "    # Resize((256, 256)), # Resize images\n",
    "    # ToTensor(), # Convert images to tensors\n",
    "    # Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize images\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing your dataset\n",
    "directory = r\"D:\\omer\\poverty_mapping_data\\clipped_data\"\n",
    "\n",
    "# Calculate sample weights\n",
    "# sample_weights = get_sample_weights(directory, class_counts)\n",
    "\n",
    "# Create a WeightedRandomSampler\n",
    "# sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = customDataset(directory=directory, transform=transforms)\n",
    "\n",
    "# train/test split\n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# setup model\n",
    "from models import load_modified_resnet50\n",
    "\n",
    "num_classes = 3\n",
    "model = load_modified_resnet50(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/35 Training:   0%|          | 0/53 [00:00<?, ?it/s]c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Epoch 1/35 Training: 100%|██████████| 53/53 [04:58<00:00,  5.63s/it]\n",
      "Epoch 1/35 Testing: 100%|██████████| 23/23 [02:02<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with accuracy: 0.7298\n",
      "Epoch 1/35, Train Loss: 0.7412, Train Accuracy: 0.6858, Test Loss: 1.2370, Test Accuracy: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/35 Training: 100%|██████████| 53/53 [00:49<00:00,  1.07it/s]\n",
      "Epoch 2/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with accuracy: 0.7451\n",
      "Epoch 2/35, Train Loss: 0.6362, Train Accuracy: 0.7180, Test Loss: 0.5893, Test Accuracy: 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 3/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/35, Train Loss: 0.6049, Train Accuracy: 0.7354, Test Loss: 0.5825, Test Accuracy: 0.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 4/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/35, Train Loss: 0.5919, Train Accuracy: 0.7497, Test Loss: 0.6259, Test Accuracy: 0.7242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 5/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with accuracy: 0.7479\n",
      "Epoch 5/35, Train Loss: 0.5614, Train Accuracy: 0.7605, Test Loss: 0.6196, Test Accuracy: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 6/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/35, Train Loss: 0.5625, Train Accuracy: 0.7425, Test Loss: 0.7698, Test Accuracy: 0.6421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 7/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/35, Train Loss: 0.5577, Train Accuracy: 0.7664, Test Loss: 0.6443, Test Accuracy: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 8/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/35, Train Loss: 0.5372, Train Accuracy: 0.7700, Test Loss: 0.6077, Test Accuracy: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 9/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with accuracy: 0.7897\n",
      "Epoch 9/35, Train Loss: 0.5229, Train Accuracy: 0.7772, Test Loss: 0.5361, Test Accuracy: 0.7897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 10/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/35, Train Loss: 0.5162, Train Accuracy: 0.7867, Test Loss: 0.5684, Test Accuracy: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 11/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/35, Train Loss: 0.5064, Train Accuracy: 0.7790, Test Loss: 0.8240, Test Accuracy: 0.7535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.21it/s]\n",
      "Epoch 12/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/35, Train Loss: 0.5317, Train Accuracy: 0.7694, Test Loss: 0.7355, Test Accuracy: 0.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 13/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/35, Train Loss: 0.5257, Train Accuracy: 0.7694, Test Loss: 1.1173, Test Accuracy: 0.5418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.21it/s]\n",
      "Epoch 14/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/35, Train Loss: 0.5212, Train Accuracy: 0.7754, Test Loss: 0.5844, Test Accuracy: 0.7507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 15/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/35, Train Loss: 0.4924, Train Accuracy: 0.7969, Test Loss: 0.5848, Test Accuracy: 0.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 16/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/35, Train Loss: 0.4956, Train Accuracy: 0.7909, Test Loss: 0.5600, Test Accuracy: 0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.21it/s]\n",
      "Epoch 17/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/35, Train Loss: 0.5105, Train Accuracy: 0.7832, Test Loss: 0.5703, Test Accuracy: 0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 18/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/35, Train Loss: 0.5237, Train Accuracy: 0.7772, Test Loss: 0.5375, Test Accuracy: 0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/35 Training: 100%|██████████| 53/53 [00:43<00:00,  1.22it/s]\n",
      "Epoch 19/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/35, Train Loss: 0.4709, Train Accuracy: 0.8065, Test Loss: 0.4808, Test Accuracy: 0.7855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/35 Training: 100%|██████████| 53/53 [01:01<00:00,  1.17s/it]\n",
      "Epoch 20/35 Testing: 100%|██████████| 23/23 [00:33<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/35, Train Loss: 0.4784, Train Accuracy: 0.8047, Test Loss: 0.8966, Test Accuracy: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/35 Training: 100%|██████████| 53/53 [01:17<00:00,  1.45s/it]\n",
      "Epoch 21/35 Testing: 100%|██████████| 23/23 [00:33<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/35, Train Loss: 0.4715, Train Accuracy: 0.7975, Test Loss: 0.5802, Test Accuracy: 0.7786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/35 Training: 100%|██████████| 53/53 [01:17<00:00,  1.46s/it]\n",
      "Epoch 22/35 Testing: 100%|██████████| 23/23 [00:33<00:00,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/35, Train Loss: 0.4774, Train Accuracy: 0.7975, Test Loss: 0.5753, Test Accuracy: 0.7298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/35 Training: 100%|██████████| 53/53 [01:16<00:00,  1.45s/it]\n",
      "Epoch 23/35 Testing: 100%|██████████| 23/23 [00:33<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/35, Train Loss: 0.4673, Train Accuracy: 0.8100, Test Loss: 0.5439, Test Accuracy: 0.7688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/35 Training: 100%|██████████| 53/53 [01:18<00:00,  1.48s/it]\n",
      "Epoch 24/35 Testing: 100%|██████████| 23/23 [00:33<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/35, Train Loss: 0.4819, Train Accuracy: 0.7957, Test Loss: 0.6128, Test Accuracy: 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/35 Training: 100%|██████████| 53/53 [01:02<00:00,  1.17s/it]\n",
      "Epoch 25/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with accuracy: 0.7911\n",
      "Epoch 25/35, Train Loss: 0.4894, Train Accuracy: 0.7987, Test Loss: 0.6307, Test Accuracy: 0.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.24it/s]\n",
      "Epoch 26/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/35, Train Loss: 0.4766, Train Accuracy: 0.7999, Test Loss: 0.6877, Test Accuracy: 0.7312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.24it/s]\n",
      "Epoch 27/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/35, Train Loss: 0.4835, Train Accuracy: 0.7957, Test Loss: 0.6106, Test Accuracy: 0.7646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.24it/s]\n",
      "Epoch 28/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/35, Train Loss: 0.4479, Train Accuracy: 0.8160, Test Loss: 0.5460, Test Accuracy: 0.7660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.25it/s]\n",
      "Epoch 29/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/35, Train Loss: 0.4767, Train Accuracy: 0.7963, Test Loss: 0.5341, Test Accuracy: 0.7730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.23it/s]\n",
      "Epoch 30/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35, Train Loss: 0.4342, Train Accuracy: 0.8160, Test Loss: 0.6189, Test Accuracy: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.25it/s]\n",
      "Epoch 31/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/35, Train Loss: 0.4711, Train Accuracy: 0.8112, Test Loss: 0.5594, Test Accuracy: 0.7451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.25it/s]\n",
      "Epoch 32/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/35, Train Loss: 0.4488, Train Accuracy: 0.8076, Test Loss: 0.5453, Test Accuracy: 0.7799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.24it/s]\n",
      "Epoch 33/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/35, Train Loss: 0.4560, Train Accuracy: 0.8100, Test Loss: 0.6336, Test Accuracy: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.24it/s]\n",
      "Epoch 34/35 Testing: 100%|██████████| 23/23 [00:17<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/35, Train Loss: 0.4228, Train Accuracy: 0.8142, Test Loss: 0.7712, Test Accuracy: 0.7061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/35 Training: 100%|██████████| 53/53 [00:42<00:00,  1.26it/s]\n",
      "Epoch 35/35 Testing: 100%|██████████| 23/23 [00:18<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/35, Train Loss: 0.4275, Train Accuracy: 0.8238, Test Loss: 1.7204, Test Accuracy: 0.6128\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = 3\n",
    "model = load_modified_resnet50(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Specify the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 35\n",
    "best_test_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Train\n",
    "    for inputs, labels in tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs} Training'):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()  # Backward pass and optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = correct_predictions / total_predictions\n",
    "\n",
    "    # Test\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_dataloader, desc=f'Epoch {epoch+1}/{num_epochs} Testing'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_loss / len(test_dataloader)\n",
    "    test_acc = correct_predictions / total_predictions\n",
    "    \n",
    "    torch.save(model.state_dict(), 'last_model.pth')\n",
    "    # Save the model if test accuracy improves\n",
    "    if test_acc > best_test_accuracy:\n",
    "        best_test_accuracy = test_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'New best model saved with accuracy: {test_acc:.4f}')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "print('Training complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  9  93   0]\n",
      " [  0 430   0]\n",
      " [  0 186   0]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.16       102\n",
      "           1       0.61      1.00      0.76       430\n",
      "           2       0.00      0.00      0.00       186\n",
      "\n",
      "    accuracy                           0.61       718\n",
      "   macro avg       0.54      0.36      0.31       718\n",
      "weighted avg       0.51      0.61      0.48       718\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\CITY3\\.conda\\envs\\i-jepaVENV\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Create classification report\n",
    "report = classification_report(true_labels, predicted_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "i-jepaVENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
